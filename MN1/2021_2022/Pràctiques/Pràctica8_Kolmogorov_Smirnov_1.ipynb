{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Práctica8_Kolmogorov_Smirnov_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseflix/DocenciaUAB/blob/master/MN1/2021_2022/Pr%C3%A0ctiques/Pr%C3%A0ctica8_Kolmogorov_Smirnov_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lyv_uztL_hM"
      },
      "source": [
        "# **Práctica 8: Test de Kolmogorov-Smirnov 1/2**\n",
        "\n",
        "<hr>\n",
        "\n",
        "**Objectivo de la práctica** \n",
        "\n",
        "Ver como aplicar el método de Kolmogorov-Smirnov para estimar parámetros de una distribución, dada una muestra de valores independientes que siguen la distribución.\n",
        "\n",
        "En esta práctica vamos a aplicar el método de Kolmogorov-Smirnov para encontrar el parámetro $\\sigma$ de una distribución Gaussiana. \n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yBZAoZ2K-8K"
      },
      "source": [
        "### <font color='orange'>**> Python #1**</font>\n",
        "\n",
        "Considera esta muestra de 50 puntos, que siguen una distribución Gaussiana:\n",
        "\n",
        "[22.3,12.9,-10.1,-36.9,-38.5,-23.4,-4.3,5.5,48.8,20.5,18.1,8.3,-37.2,-8.1,-5.6,41.4,-6.5,-16.7,-12.8,-30.0,11.9,-12.6,6.6,-24.8,6.0,34.5,-31.2,63.3,-19.8,22.1,-42.5,18.9,-0.0,-13.1,-37.4,-68.1,20.7,59.1,-37.0,-31.9,-92.2,-29.9,11.9,6.5,13.8,2.6,-33.9,27.3,17.8,-18.6]\n",
        "\n",
        "Vamos a usar el método de Komogorov-Smirnov para calcular la $\\sigma_{óptima}$, la que mejor ajusta a la distribución de probabilidad de la muestra.\n",
        "\n",
        "Primero vamos a calcular el valor medio ($\\mu_m$) y la varianza ($\\sigma_m$) de la muestra, ya que sabemos que son buenos estimadores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4pbieMPL60e"
      },
      "source": [
        "# Código"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHsb26aOd1n"
      },
      "source": [
        "### <font color='green'>**> Ejercicio #1**</font>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<font color='green'>Esta práctica de 1h no tiene entrega, pero se tienen que realizar los ejercicios de programación durante la clase...</font>\n",
        "\n",
        "<hr>\n",
        "\n",
        "Podemos calcular los parámetros óptimos que se ajustan mejor a tu muestra usando la función cumulativa de tu muestra y comparando con diferentes funciones cumulativas de prueba (que van cambiando sus parámetros).\n",
        "\n",
        "Para cada punto de tu muestra puedes calcular la diferencia de la función cumulativa de tu muestra con el valor cumulativo que obtienes con la función de test en ése mismo punto, y quedarte con el valor de desviación máxima: el método simple de Kolmogorov-Smirnov (KS). La función de test que mejor se ajusta es aquella que está 'más' cerca de tu función cumulativa de muestra de acuerdo con esta distancia $d_{max}$. Usando diferentes distribuciones de test, uno puede obtener aquella que minimiza $d_{max}$.\n",
        "\n",
        "En nuestro caso, para cada distribución de test $i$, el valor $d_{max,i}$ se calcula para cada función de test $i$ como:\n",
        "\n",
        "<br>\n",
        "\n",
        "$$\n",
        "d_{max,i} = max_{n=1}^{50}( | CDF_{muestra}(x_n) - CDF_{Gaussiana}(x_n, \\mu_m, \\sigma_i) | )\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "Primero vamos a hacer una gráfica de la función cumulativa de la muestra: en este caso, para cada valor $𝑥_i$ de tu muestra, la función cumulativa incrementa en un factor 1/50, así hasta llegar a un valor máximo de 1. \n",
        "\n",
        "También vamos a dibujar 2 funciones cumulativas de test, para ver como se acercan a la función cumulativa de tu muestra. Considera dos gaussianas con valor medio $\\mu$=-4.45 (valor obtenido antes) y $\\sigma_1$=10 y $\\sigma_2$=28."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmCfawIFOfiO"
      },
      "source": [
        "# Ordena tu muestra usando la función np.sort() y construye la y cumulativa\n",
        "\n",
        "# Genera los pares de puntos (x,y) para las dos gaussianas con sigma1 = 10 y sigma2 = 28\n",
        "\n",
        "# Haz las gráficas, con sus labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmPnYU4mMsTo"
      },
      "source": [
        "### <font color='orange'>**> Python #2**</font>\n",
        "\n",
        "Vamos a calcular ahora la $\\sigma_{óptima}$ usando la función cumulativa de tu muestra y comparando con diferentes funciones cumulativas de test. Fija el valor medio de la distribución Gaussiana en $\\mu_m$ y considera 1000 pasos equidistantes entre $\\sigma_{inf}$=15 y $\\sigma_{sup}$=45. En este caso, para cada valor $x_i$ de tu muestra, la función cumulativa te incrementa en un factor 1/50, y queda fijada. \n",
        "\n",
        "Haz una gráfica de los valores $d_{max}$ en el rango [$\\sigma_{inf}$,$\\sigma_{sup}$] y evalúa cual es el $\\sigma_{óptimo}$ (el que minimiza la función $d_{max}$). El valor $d_{max,i}$ se calcula para cada función de test $i$ como:\n",
        "\n",
        "<br>\n",
        "\n",
        "$$\n",
        "d_{max,i} = max_{n=1}^{50}( | CDF_{muestra}(x_n) - CDF_{Gaussiana}(x_n, \\mu_m, \\sigma_i) | )\n",
        "$$\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDVRm3DCNluG"
      },
      "source": [
        "# Haz un bucle en el rango de sigmas de test, y calcula para cada una de ellas dmax\n",
        "\n",
        "# Haz una gráfica de dmax vs sigmas de test\n",
        "\n",
        "# Imprime el valor de sigma que minimiza dmax:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m82Y2yDYZdh2"
      },
      "source": [
        "### <font color='red'>**> Material Adicional**</font>\n",
        "\n",
        "Para estar menos afectado por las colas de las distribuciones, se usan métodos en KS donde se introduce el concepto de 'peso': es decir, tener más en cuenta los valores más probables y menos las colas. \n",
        "\n",
        "Una variante más completa de Kolmogorov-Smirnov se emplea a menudo. Para cada punto de tu muestra puedes calcular la diferencia de la función cumulativa de tu muestra con el valor cumulativo que obtienes con la función de test en ése mismo punto, aplicando un peso y haciendo una suma cumulativa de las diferencias o distancias $d_{KS}$. En vez de usar la desviación máxima, para cada punto de evaluación, se multiplica la distancia por el valor de la pdf en aquel punto (para que pesen más los valores más probables), y se suman todos los valores absolutos de distancias que se evalúan para cada punto, así se promedian todas las diferencias.\n",
        "\n",
        "En este ejemplo, sería aplicar esta fórmula:\n",
        "\n",
        "$$\n",
        "d_{KS_i} = \\sum_{n=1}^{50}( | CDF_{muestra}(x_n) - CDF_{Gaussiana}(x_n,\\mu,\\sigma_i) | · PDF_{Gaussiana}(x_n,\\mu,\\sigma_i) )\n",
        "$$\n",
        "\n",
        "<br>"
      ]
    }
  ]
}